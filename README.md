Deal-Pulse Coding Challenge ‚Äì README
====================================

This file explains everything a candidate needs
to know: the **problem statement**, required objectives, how to run
the scaffold, and a couple of smoke-test commands to make sure
their environment is ready before they write a single line of code.

-------------------------------------------------------------------
1  Problem statement
-------------------------------------------------------------------

Mundos needs a micro-dashboard called **Deal-Pulse** that ingests a
JSON dump of early-stage ‚Äúdeals‚Äù, exposes two typed REST endpoints,
and renders a single-page React UI that surfaces continent-level
trends plus drill-down to individual deals.

-------------------------------------------------------------------
2  Objectives (what you must build in ‚â§ 60 min)
-------------------------------------------------------------------

 1. **CLI ingest** ‚Äì `loadDeals("deals.json")` must
    * parse 500 rows of heterogeneous JSON,
    * skip invalid rows with logged errors,
    * pre-compute aggregates so later queries are O(1).

 2. **Endpoint A ‚Äì GET /deals/summary**
    Returns an array of:
    `{ continent, total, median_valuation }`.

 3. **Endpoint B ‚Äì GET /deals/:id**
    Returns the chosen deal plus `days_since_announced`.

 4. **Dashboard React UI**
    * Fetches `/deals/summary` on mount,
    * Renders a table (or cards) per continent,
    * Clicking a row fetches `/deals/:id` and shows a modal.

 5. **Error handling**
    JSON body `{ code, message }`, HTTP status 4xx/5xx,
    plus ISO-timestamp console logs.

-------------------------------------------------------------------
3  Repository layout (scaffold overview)
-------------------------------------------------------------------

# ![Deal-Pulse wireframe](assets/dashboard-wireframe.png)

-------------------------------------------------------------------
4  Getting started ‚Äì local setup
-------------------------------------------------------------------

 ```bash
 # clone the repo (or open the Codespace link)
 pnpm install        # deps in <10 s
 pnpm dev            # API :4000   UI :5173
 curl localhost:4000/ping        # ‚Üí {"message":"pong"}
 open http://localhost:5173      # heading renders
 ```

 If either server crashes, something is wrong with your environment;
 fix before writing feature code.

-------------------------------------------------------------------
5  Smoke-test checklist (should pass instantly)
-------------------------------------------------------------------

 1. **Health check**
    `curl localhost:4000/ping` ‚Üí `{"message":"pong"}`

 2. **Data presence**
    `node -e "console.log(require('./deals.json').length)"` ‚Üí `500`

 3. **TypeScript compile**
    `pnpm build` completes without errors (pre-TODO code only).

-------------------------------------------------------------------
6  Dataset notes
-------------------------------------------------------------------

‚Ä¢ `deals.json` was freshly generated before your interview; it
  contains random field names (`valuation_usd` / `val_usd` / `price`)
  to discourage hard-coding. Assume nothing‚Äîinspect the data.

‚Ä¢ Do **not** regenerate or modify this file; treat it as a read-only
  external dump.

-------------------------------------------------------------------
7  Allowed resources
-------------------------------------------------------------------

‚úÖ Public docs, MDN, StackOverflow, npm-js search  
‚ùå Copy-pasting large code blobs without explaining them  
‚úÖ Any VS Code extensions already in the Codespace  

-------------------------------------------------------------------
8  Submission / demo
-------------------------------------------------------------------

With 10 minutes left the interviewer will ask you to:
 ‚Ä¢ hit `/deals/summary` in the browser,  
 ‚Ä¢ click through a row ‚Üí modal,  

Commit all work; no extra README edits required.

-------------------------------------------------------------------

Good luck, and have fun turning data into insight! üöÄ
-------------------------------------------------------------------
